# -*- coding: utf-8 -*-
"""EmployeePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KAJ2iK4LbnTiykKQAU-SkbLYiTDjBm9q
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Logistic_Regression

import pandas as pd
import numpy as np
import random as rnd

import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib

import warnings
warnings.filterwarnings('ignore')
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning, module="sklearn")
from sklearn.model_selection import GridSearchCV

Data = pd.read_csv("HR_comma_sep.csv")
Data.head()

print("Number of featues: ", Data.shape[0])
print("Number of samples: ", Data.shape[1])
print("Featues: ", Data.columns.values)

Data.info()

Data["Department"].value_counts()

Data["Department"] = Data["Department"].map({"sales": 0, "technical": 1, "support": 2, "IT": 3, "product_mng": 4, "marketing": 5, "RandD": 6, "accounting": 7, "hr": 8, "management": 9}).astype(int)
print(Data["Department"].value_counts())

Data["salary"].value_counts()

Data["salary"] = Data["salary"].map({"low": 0, "medium": 1, "high": 2}).astype(int)
print(Data["salary"].value_counts())

Data.dtypes

fig, ax = plt.subplots(figsize=(10, 5))
corr_matrix = Data.corr()
sns.heatmap(corr_matrix, annot = True, linewidth = .2)

X_train_data = Data.drop("left", axis = 1)
y_train_data = Data["left"]
x_test_data = Data

X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train_data, test_size = 0.05)
print("Shape of X_train", X_train.shape, "\nShape of y_train", y_train.shape)
print("Shape of X_val", X_val.shape, "\nShape of y_val", y_val.shape)

print(y_val)

model = LogisticRegression(max_iter = 20)
param_grid = dict()
param_grid['solver'] = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']

grid = GridSearchCV(model, param_grid, refit = True)
grid.fit(X_train, y_train)

print("Best params: ", grid.best_params_)

model = LogisticRegression(solver = "liblinear", max_iter = 20)
model.fit(X_train, y_train)
accuracy = round(model.score(X_train, y_train) * 100, 2)
print("Training Accuracy of logictic regression:", accuracy, "\n")

model = LogisticRegression(solver = "liblinear", max_iter = 20)

model.fit(X_train, y_train)
print("In validation Dataset, Total number of employees:", len(y_val))
print("Actual Result in validation dataset")
print("Left", sum(y_val!=0))
print("Stay", sum(y_val==0))

y_pred = model.predict(X_val)
print("\nPrediction of Logistic Regression")
print("Left", sum(y_pred!=0))
print("Stay", sum(y_pred==0))

print("=========Classification report=======")
print(classification_report(y_val, y_pred))